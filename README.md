# Python-网络爬虫
1 **概述**

​		网络爬虫（又称为网页[蜘蛛](https://baike.baidu.com/item/蜘蛛/8135707)，网络机器人，在[FOAF](https://baike.baidu.com/item/FOAF)社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取[万维网](https://baike.baidu.com/item/万维网/215515)信息的程序或者脚本。

​		简单来说，爬虫就是一个模拟浏览器发起请求，然后将服务器响应的数据(html，json等等)进行有用信息提取，然后保存起来的一个过程。

------

2 **爬虫原理**

​		爬虫就是获取网页并提取和保存信息的自动化程序。

  ![image-20190924220631830](https://mega.nz/#!KBxTEAKY)
​		由上图可得，我们的爬虫程序其实就是由三个步骤组成：

1. 获取网页

   ​		获取网页，其实就是模拟浏览器访问获取网页的源代码。Python提供了很多类库来实现这个操作，如urllib、requests等等。

2. 提取信息

   ​		提取信息，即从网页源代码中提取出有用数据。Python提供了很多类库来实现这个操作，如re、xpath、bs4等等。

3. 保存数据

   ​		保存数据，就是将我们提取出来的有用信息进行持久化的操作。如保存为txt、jpg等，也可以保存到数据库(MySQL、Redis等等)。

   通过实现上面三个步骤，其实我们就完成了我们的一个简单的爬虫程序。这个爬虫程序就可以代替我们去自动化的爬取一些有用信息了。
